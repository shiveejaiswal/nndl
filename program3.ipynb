{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a0b235-2ea7-4b8b-8715-5dffca1e2292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step \n",
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/30\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 0.3253 - val_loss: 0.1413\n",
      "Epoch 2/30\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - loss: 0.1331 - val_loss: 0.1132\n",
      "Epoch 3/30\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1105 - val_loss: 0.1013\n",
      "Epoch 4/30\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - loss: 0.1011 - val_loss: 0.0954\n",
      "Epoch 5/30\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - loss: 0.0957 - val_loss: 0.0915\n",
      "Epoch 6/30\n",
      "\u001b[1m 28/235\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0929"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "# Define the Autoencoder\n",
    "encoding_dim = 64\n",
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(encoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train the Autoencoder\n",
    "history = autoencoder.fit(x_train, x_train,\n",
    "                epochs=30,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "\n",
    "# Plot accuracy and loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Autoencoder Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "decoder=Model(encoded,decoded)\n",
    "\n",
    "encoded_img = encoder.predict(x_test)\n",
    "decoded_img = decoder.predict(encoded_img)\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(5):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, 5, i + 1 + 5)\n",
    "    plt.imshow(decoded_img[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "# Encode the data using trained Autoencoder\n",
    "encoded_train = encoder.predict(x_train)\n",
    "encoded_test = encoder.predict(x_test)\n",
    "\n",
    "# Apply K-NN on encoded data\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(encoded_train, y_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_pred = knn.predict(encoded_test)\n",
    "\n",
    "# Evaluate the K-NN model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"K-NN accuracy on encoded data: {acc * 100:.2f}%\")\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "# Classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcdfa0f-d693-495e-9665-773fb33f71bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
